{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b41b7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from vae_earlystopping import EarlyStopping\n",
    "from torch.utils.data import  DataLoader, Dataset\n",
    "from model_vae import CVAE,cvae_loss_each,cvae_loss_optimized,cvae_loss\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_data = np.load('./data/metal.npy',allow_pickle = True)\n",
    "c_data = np.load('./data/reaction.npy',allow_pickle = True)\n",
    "sup_data = np.load('./data/support.npy',allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c47cb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3544, 24) (1182, 24) (1182, 24)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,c_train,c_test = train_test_split(x_data,c_data,test_size= 0.4, shuffle=False)\n",
    "x_val,x_test,c_val,c_test = train_test_split(x_test,c_test,test_size = 0.5, shuffle=False)\n",
    "print(x_train.shape,x_val.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02b1ef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "x_scaler = StandardScaler()\n",
    "c_scaler = StandardScaler()\n",
    "# x정규화\n",
    "x_train = x_scaler.fit_transform(x_train)\n",
    "x_test = x_scaler.fit_transform(x_test)\n",
    "x_val = x_scaler.fit_transform(x_val)\n",
    "# c정규화\n",
    "c_train = c_scaler.fit_transform(c_train)\n",
    "c_val = c_scaler.transform(c_val)\n",
    "c_test = c_scaler.transform(c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d02a53c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "x_val   = torch.tensor(x_val,   dtype=torch.float32)\n",
    "x_test  = torch.tensor(x_test,  dtype=torch.float32)\n",
    "\n",
    "c_train = torch.tensor(c_train, dtype=torch.float32)\n",
    "c_val   = torch.tensor(c_val,   dtype=torch.float32)\n",
    "c_test  = torch.tensor(c_test,  dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12091142",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = x_train.shape[1]\n",
    "c_dim = c_train.shape[1]\n",
    "z_dim = 16\n",
    "x_hat, mu, logvar = model(x_train,c_train)\n",
    "loss, recon,kl = cvae_loss(x_hat,x_train,mu,logvar,beta = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71accf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "z_dim = 16\n",
    "epochs = 200\n",
    "train_dataset = TensorDataset(x_train,c_train)\n",
    "val_dataset = TensorDataset(x_val,c_val)\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle= True)\n",
    "val_loader = DataLoader(val_dataset,batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "814589ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CVAE(x_dim = x_dim,c_dim=c_dim,z_dim = z_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65984505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200] Train Loss: 0.043043 | Val Loss: 0.691599\n",
      "Epoch [20/200] Train Loss: 0.039732 | Val Loss: 0.714723\n",
      "Epoch [40/200] Train Loss: 0.037809 | Val Loss: 0.749813\n",
      "Epoch [60/200] Train Loss: 0.038721 | Val Loss: 0.756095\n",
      "Epoch [80/200] Train Loss: 0.034712 | Val Loss: 0.785348\n",
      "Epoch [100/200] Train Loss: 0.042005 | Val Loss: 0.804880\n",
      "Epoch [120/200] Train Loss: 0.031831 | Val Loss: 0.829445\n",
      "Epoch [140/200] Train Loss: 0.034393 | Val Loss: 0.893272\n",
      "Epoch [160/200] Train Loss: 0.031027 | Val Loss: 0.853076\n",
      "Epoch [180/200] Train Loss: 0.032943 | Val Loss: 0.878430\n",
      "Epoch [200/200] Train Loss: 0.040108 | Val Loss: 0.873611\n"
     ]
    }
   ],
   "source": [
    "## x_test,c_test가 torch tensor로 만들어진 뒤에 실행\n",
    "test_loader = DataLoader(\n",
    "    TensorDataset(x_test,c_test),\n",
    "    batch_size = 128,\n",
    "    shuffle = False\n",
    ")\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "early = EarlyStopping(patience = 30, min_delta=1e-4)\n",
    "for epoch in range(1,epochs+1):\n",
    "    model.train()\n",
    "    train_total_loss = 0.0\n",
    "    #batch로 실행하기\n",
    "    for batch_x,batch_c in train_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_c = batch_c.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x_hat,mu,logvar = model(batch_x,batch_c)\n",
    "        loss,recon,kl = cvae_loss(x_hat,batch_x,mu,logvar,beta = 0.01)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_total_loss +=loss.item()\n",
    "    avg_train_loss = train_total_loss/len(train_loader)\n",
    "    ## 검증하기\n",
    "    model.eval()\n",
    "    val_total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for v_x,v_c in val_loader:\n",
    "            v_x = v_x.to(device)\n",
    "            v_c = v_c.to(device)\n",
    "            v_hat,v_mu,v_logvar = model(v_x,v_c)\n",
    "            v_loss,_,_ = cvae_loss(v_hat,v_x,v_mu,v_logvar,beta = 0.01)\n",
    "            val_total_loss += v_loss\n",
    "    avg_val_loss = val_total_loss/len(val_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    if epoch % 20 == 0 or epoch == 1:\n",
    "        print(f\"Epoch [{epoch}/{epochs}] Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce63029",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 200\n",
    "train\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
    "train_total_loss = []\n",
    "val_total_loss = \n",
    "for epoch in range(1,epochs+1):\n",
    "    model.train()\n",
    "    train_total_loss=0\n",
    "    for batch_x,batch_c in train_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_c = batch_c.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x_hat,mu,logvar\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce40e589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c040172",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
    "epochs = 200\n",
    "\n",
    "for epoch in range(1,epochs+1):\n",
    "    model.train()\n",
    "    train_total_loss = 0\n",
    "    for batch_x,batch_c in train_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_c = batch_c.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss,recon,kl = CVAE(batch_x,batch_c)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_total_loss +=loss.item()\n",
    "    avg_train_loss = train_total_loss/len(train_loader)\n",
    "    model.eval()\n",
    "    val_total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for v_x,v_c in val_loader:\n",
    "            v_x = v_x.to(device)\n",
    "            v_c = v_c.to(device)\n",
    "            v_hat,v_mu,v_logvar = model(v_x,v_c)\n",
    "            v_loss,_,_ = cvae_loss(v_hat,v_x,v_mu)\n",
    "            val_total_loss += v_loss.item()\n",
    "        avg_val_loss = val_total_loss/len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f55ad75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
