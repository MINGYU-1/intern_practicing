{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f42b2e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26439ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.load('./data/metal.npy')\n",
    "c_data = np.load('./data/reaction.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a2e9cf",
   "metadata": {},
   "source": [
    "### train_test_split을 활용해 데이터를 train,val,test로 해서 0.6,0.2,0.2로 나눠서 구분\n",
    "- random_state = 21로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23700e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,c_train,c_test = train_test_split(x_data,c_data,random_state = 21,test_size = 0.4)\n",
    "x_val,x_test,c_val,c_test = train_test_split(x_test,c_test,random_state = 21, test_size = 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2de9846",
   "metadata": {},
   "source": [
    "### MinMaxScaler을 활용해서 데이터를 normalization진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "403e5865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x_scaler = MinMaxScaler()\n",
    "c_scaler = MinMaxScaler()\n",
    "x_train = x_scaler.fit_transform(x_train)\n",
    "c_train = c_scaler.fit_transform(c_train)\n",
    "x_val,x_test = [x_scaler.transform(x) for x in [x_val,x_test]]\n",
    "c_val,c_test = [c_scaler.transform(c) for c in [c_val,c_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afee41d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./torch/c_scaler.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "joblib.dump(x_scaler,'./torch/x_scaler.pkl')\n",
    "joblib.dump(c_scaler,'./torch/c_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45c66958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x_train,x_val,x_test = [torch.tensor(x, dtype = torch.float32) for x in [x_train,x_val,x_test]]\n",
    "c_train,c_val,c_test = [torch.tensor(c, dtype = torch.float32) for c in [c_train,c_val,c_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc868edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "train_data = [x_train,c_train]\n",
    "val_data = [x_val,c_val]\n",
    "test_data = [x_test,c_test]\n",
    "train_data = TensorDataset(*train_data)\n",
    "val_data = TensorDataset(*val_data)\n",
    "test_data = TensorDataset(*test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21af98eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = [train_data,val_data,test_data]\n",
    "train_loader,val_loader,test_loader = [DataLoader(x,batch_size = 64,shuffle=False) for x in datas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05928c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('torch',exist_ok = True)\n",
    "torch.save(train_loader,\"torch/train_loader.pt\")\n",
    "torch.save(val_loader,\"torch/val_loader.pt\")\n",
    "torch.save(test_loader,\"torch/test_loader.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
