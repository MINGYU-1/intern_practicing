{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df25e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일단 1층만 만들기\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self,x_dim,c_dim,z_dim=16,h1 = 32,h2 =64):\n",
    "        super().__init__()\n",
    "        self.x_dim = x_dim\n",
    "        self.c_dim = c_dim\n",
    "        self.z_dim = z_dim\n",
    "        # encoder\n",
    "        self.enc1 = nn.Linear(x_dim+c_dim,h1)\n",
    "        self.enc2 = nn.Linear(h1,h2)\n",
    "        self.mu = nn.Linear(h2,z_dim)\n",
    "        self.logvar = nn.Linear(h2,z_dim)\n",
    "        # decoder\n",
    "        self.dec1 = nn.Linear(z_dim+c_dim,h2) # 16+9 ,64\n",
    "        self.dec2 = nn.Linear(h2,h1) # 64,32\n",
    "        self.out = nn.Linear(h1,x_dim) # 32 23\n",
    "    def encoder(self,x,c):\n",
    "        h = torch.cat([x,c],dim = 1)\n",
    "        h = F.relu(self.enc1(h))\n",
    "        h = F.relu(self.enc2(h))\n",
    "        mu = self.mu(h)\n",
    "        logvar = self.logvar(h)\n",
    "        return mu, logvar\n",
    "        # reparameterize\n",
    "    def reparameterize(self,mu,logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + std * eps\n",
    "        # decoder\n",
    "    def decoder(self,z,c):\n",
    "        h = torch.cat([z,c],dim = 1)\n",
    "        h = F.relu(self.dec1(h))\n",
    "        h = F.relu(self.dec2(h))\n",
    "        x_hat = self.out(h)\n",
    "        return x_hat\n",
    "    def forward(self,x,c):\n",
    "        mu,logvar = self.encoder(x,c)\n",
    "        z = self.reparameterize(mu,logvar)\n",
    "        x_hat = self.decoder(z,c)\n",
    "        return x_hat,mu,logvar\n",
    "\n",
    "def cvae_loss_by_nickel_presence(\n",
    "    x_hat, x, mu, logvar,\n",
    "    beta=1.0,\n",
    "    nickel_weight=0.8,   # 니켈 항목에 주는 비중(0~1)\n",
    "    ni_idx=7,\n",
    "    zero_thr=1e-6\n",
    "):\n",
    "    \"\"\"\n",
    "    반환:\n",
    "      - loss_no_ni: 니켈 없는 샘플(ni==0)에 대한 loss\n",
    "      - loss_has_ni: 니켈 있는 샘플(ni>0)에 대한 loss (니켈 가중치 포함)\n",
    "      - loss_total: 전체 loss (둘을 샘플수로 가중 평균)\n",
    "      - 로그용 recon/kl 등\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 마스크: 니켈 유무 ---\n",
    "    ni_true = x[:, ni_idx]                         # [B]\n",
    "    mask_no_ni  = (ni_true <= zero_thr)            # [B]\n",
    "    mask_has_ni = ~mask_no_ni                      # [B]\n",
    "\n",
    "    # --- 공통: KL(배치 평균) ---\n",
    "    kl_vec = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)  # [B]\n",
    "\n",
    "    # --- feature 인덱스: 니켈 제외 ---\n",
    "    idx_no_ni_feat = list(range(0, ni_idx)) + list(range(ni_idx + 1, x.size(1)))\n",
    "\n",
    "    if mask_no_ni.any():\n",
    "        x0_hat = x_hat[mask_no_ni]\n",
    "        x0     = x[mask_no_ni]\n",
    "        kl0    = kl_vec[mask_no_ni].mean()\n",
    "\n",
    "        recon0_all = F.mse_loss(x0_hat, x0, reduction='mean')\n",
    "        recon0_no_ni = F.mse_loss(x0_hat[:, idx_no_ni_feat], x0[:, idx_no_ni_feat], reduction='mean')\n",
    "        recon0_ni = F.mse_loss(x0_hat[:, ni_idx:ni_idx+1], x0[:, ni_idx:ni_idx+1], reduction='mean')\n",
    "\n",
    "        # 니켈 없는 경우는 \"니켈을 0으로 붙이기\"가 목적이므로\n",
    "        # 니켈 항목 recon을 더 주고 싶으면 가중치를 주면 됨(예: nickel_weight를 여기에도 활용 가능)\n",
    "        recon0 = (1 - nickel_weight) * recon0_no_ni + nickel_weight * recon0_ni\n",
    "\n",
    "        loss_no_ni = recon0 + beta * kl0\n",
    "    else:\n",
    "        loss_no_ni = torch.tensor(0.0, device=x.device)\n",
    "        recon0_all = torch.tensor(0.0, device=x.device)\n",
    "        recon0_no_ni = torch.tensor(0.0, device=x.device)\n",
    "        recon0_ni = torch.tensor(0.0, device=x.device)\n",
    "        kl0 = torch.tensor(0.0, device=x.device)\n",
    "\n",
    "    if mask_has_ni.any():\n",
    "        x1_hat = x_hat[mask_has_ni]\n",
    "        x1     = x[mask_has_ni]\n",
    "        kl1    = kl_vec[mask_has_ni].mean()\n",
    "\n",
    "        recon1_all = F.mse_loss(x1_hat, x1, reduction='mean')\n",
    "        recon1_no_ni = F.mse_loss(x1_hat[:, idx_no_ni_feat], x1[:, idx_no_ni_feat], reduction='mean')\n",
    "        recon1_ni = F.mse_loss(x1_hat[:, ni_idx:ni_idx+1], x1[:, ni_idx:ni_idx+1], reduction='mean')\n",
    "\n",
    "        # 니켈 있는 경우: 니켈 항목을 더 크게 반영\n",
    "        recon_has_ni = (1 - nickel_weight) * recon1_no_ni + nickel_weight * recon1_ni\n",
    "\n",
    "        loss_has_ni = recon_has_ni + beta * kl1\n",
    "    else:\n",
    "        loss_has_ni = torch.tensor(0.0, device=x.device)\n",
    "        recon1_all = torch.tensor(0.0, device=x.device)\n",
    "        recon1_no_ni = torch.tensor(0.0, device=x.device)\n",
    "        recon1_ni = torch.tensor(0.0, device=x.device)\n",
    "        kl1 = torch.tensor(0.0, device=x.device)\n",
    "\n",
    "    # ========== (C) 전체 loss: 샘플 수로 가중 평균 ==========\n",
    "    n0 = mask_no_ni.sum().item()\n",
    "    n1 = mask_has_ni.sum().item()\n",
    "    if n0 + n1 > 0:\n",
    "        loss_total = (loss_no_ni * n0 + loss_has_ni * n1) / (n0 + n1)\n",
    "    else:\n",
    "        loss_total = torch.tensor(0.0, device=x.device)\n",
    "\n",
    "    # 로그 반환\n",
    "    logs = {\n",
    "        \"n_no_ni\": n0,\n",
    "        \"n_has_ni\": n1,\n",
    "        \"loss_no_ni\": loss_no_ni.detach(),\n",
    "        \"loss_has_ni\": loss_has_ni.detach(),\n",
    "        \"loss_total\": loss_total.detach(),\n",
    "\n",
    "        \"recon_no_ni_all\": recon0_all.detach(),\n",
    "        \"recon_no_ni_except\": recon0_no_ni.detach(),\n",
    "        \"recon_no_ni_ni\": recon0_ni.detach(),\n",
    "        \"kl_no_ni\": kl0.detach(),\n",
    "\n",
    "        \"recon_has_ni_all\": recon1_all.detach(),\n",
    "        \"recon_has_ni_except\": recon1_no_ni.detach(),\n",
    "        \"recon_has_ni_ni\": recon1_ni.detach(),\n",
    "        \"kl_has_ni\": kl1.detach(),\n",
    "    }\n",
    "\n",
    "    return loss_total, loss_no_ni, loss_has_ni, logs\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
